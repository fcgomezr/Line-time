{"0f6f71f7-c0df-4792-89e1-8604dab13486_21":{"balanced_accuracy":[0.7220819046878098],"log_loss":[0.5312072706137217],"f1_score_weighted":[0.7574610586763234],"precision_score_micro":[0.7040971168437026],"f1_score_micro":[0.7040971168437026],"average_precision_score_weighted":[0.9204293715196785],"average_precision_score_macro":[0.7129301301492308],"average_precision_score_micro":[0.8323439499916359],"norm_macro_recall":[0.4441638093756195],"recall_score_micro":[0.7040971168437026],"AUC_weighted":[0.861480197166975],"precision_score_weighted":[0.8756284739379083],"recall_score_macro":[0.7220819046878098],"weighted_accuracy":[0.6996319805022906],"f1_score_macro":[0.5840791028109981],"accuracy":[0.7040971168437026],"precision_score_macro":[0.5969717521527215],"matthews_correlation":[0.293500742206834],"AUC_micro":[0.8309567307803012],"AUC_macro":[0.8614801971669751],"recall_score_weighted":[0.7040971168437026]},"0f6f71f7-c0df-4792-89e1-8604dab13486_30":{"f1_score_weighted":[0.8675066697235122],"AUC_macro":[0.9281958591971429],"precision_score_micro":[0.9007587253414264],"f1_score_micro":[0.9007587253414264],"AUC_micro":[0.9737530308717166],"average_precision_score_weighted":[0.9470311070568083],"AUC_weighted":[0.9281958591971429],"matthews_correlation":[0.3187183462199802],"precision_score_macro":[0.8758500772797526],"log_loss":[0.2292238675952688],"average_precision_score_macro":[0.7969693494944702],"precision_score_weighted":[0.8959103648683194],"balanced_accuracy":[0.5675677553084485],"average_precision_score_micro":[0.9747660084035891],"weighted_accuracy":[0.9834810305373748],"f1_score_macro":[0.5923432191895104],"recall_score_micro":[0.9007587253414264],"recall_score_weighted":[0.9007587253414264],"accuracy":[0.9007587253414264],"norm_macro_recall":[0.135135510616897],"recall_score_macro":[0.5675677553084485]},"0f6f71f7-c0df-4792-89e1-8604dab13486_3":{"AUC_macro":[0.9190168695945333],"f1_score_weighted":[0.8728527744232011],"matthews_correlation":[0.5281574732734101],"average_precision_score_micro":[0.8991166534038151],"precision_score_micro":[0.8534142640364188],"average_precision_score_macro":[0.7589900830738389],"accuracy":[0.8534142640364188],"precision_score_macro":[0.6999446221350052],"recall_score_micro":[0.8534142640364188],"norm_macro_recall":[0.6975689408295314],"AUC_micro":[0.9183609690499929],"AUC_weighted":[0.9190168695945333],"weighted_accuracy":[0.8545637165588769],"average_precision_score_weighted":[0.9376121821823153],"f1_score_macro":[0.7374187933360008],"recall_score_macro":[0.8487844704147657],"log_loss":[0.3724055159007936],"precision_score_weighted":[0.9152062098157044],"f1_score_micro":[0.8534142640364188],"recall_score_weighted":[0.8534142640364188],"balanced_accuracy":[0.8487844704147657]},"0f6f71f7-c0df-4792-89e1-8604dab13486_0":{"average_precision_score_macro":[0.8151093723721079],"recall_score_micro":[0.9116843702579667],"average_precision_score_micro":[0.9806603102489483],"average_precision_score_weighted":[0.9531771295804466],"recall_score_macro":[0.7513392683482543],"balanced_accuracy":[0.7513392683482543],"weighted_accuracy":[0.9514937218005303],"matthews_correlation":[0.5323740218566827],"AUC_weighted":[0.9450464668693167],"f1_score_micro":[0.9116843702579667],"log_loss":[0.17775706110025447],"AUC_micro":[0.979695082216353],"recall_score_weighted":[0.9116843702579667],"precision_score_macro":[0.7819118765348991],"norm_macro_recall":[0.5026785366965085],"f1_score_weighted":[0.9091539479147899],"f1_score_macro":[0.7653697272147331],"precision_score_micro":[0.9116843702579667],"AUC_macro":[0.9450464668693166],"accuracy":[0.9116843702579667],"precision_score_weighted":[0.9072720074188747]},"0f6f71f7-c0df-4792-89e1-8604dab13486_28":{"norm_macro_recall":[0.37103290376717846],"AUC_macro":[0.9298458637354658],"balanced_accuracy":[0.6855164518835892],"precision_score_macro":[0.7876086244823646],"average_precision_score_micro":[0.9771015060033911],"recall_score_micro":[0.9083459787556905],"precision_score_weighted":[0.896276493147234],"average_precision_score_weighted":[0.9473883104711966],"average_precision_score_macro":[0.7969160199391022],"matthews_correlation":[0.4619789239568743],"recall_score_weighted":[0.9083459787556905],"AUC_micro":[0.9760192133664609],"log_loss":[0.22016323531640344],"f1_score_macro":[0.7214524367768216],"AUC_weighted":[0.9298458637354657],"weighted_accuracy":[0.9636685228413189],"f1_score_weighted":[0.898513121045057],"precision_score_micro":[0.9083459787556905],"accuracy":[0.9083459787556905],"f1_score_micro":[0.9083459787556905],"recall_score_macro":[0.6855164518835892]},"0f6f71f7-c0df-4792-89e1-8604dab13486_5":{"balanced_accuracy":[0.5861721006136924],"matthews_correlation":[0.3264677270834346],"AUC_weighted":[0.8964808547607008],"log_loss":[0.2442606150560668],"precision_score_weighted":[0.8840533097056155],"recall_score_macro":[0.5861721006136924],"precision_score_macro":[0.8092102202104395],"f1_score_micro":[0.9001517450682853],"average_precision_score_micro":[0.9688287107163841],"weighted_accuracy":[0.9781043977806846],"f1_score_macro":[0.6178600472856574],"norm_macro_recall":[0.1723442012273848],"recall_score_weighted":[0.9001517450682853],"AUC_micro":[0.9674386860120521],"f1_score_weighted":[0.872739945318913],"precision_score_micro":[0.9001517450682853],"average_precision_score_macro":[0.7427903820139726],"accuracy":[0.9001517450682853],"average_precision_score_weighted":[0.9315568893749121],"recall_score_micro":[0.9001517450682853],"AUC_macro":[0.8964808547607007]},"0f6f71f7-c0df-4792-89e1-8604dab13486_6":{"balanced_accuracy":[0.5929351279158724],"weighted_accuracy":[0.975667643981923],"accuracy":[0.8995447647951441],"average_precision_score_micro":[0.9695227511129372],"f1_score_macro":[0.6259663822605774],"recall_score_weighted":[0.8995447647951441],"AUC_macro":[0.9030188182948131],"log_loss":[0.23645540101980647],"AUC_micro":[0.9685430401053696],"recall_score_macro":[0.5929351279158724],"norm_macro_recall":[0.18587025583174488],"precision_score_macro":[0.7915243059187207],"precision_score_weighted":[0.88123145543058],"precision_score_micro":[0.8995447647951441],"matthews_correlation":[0.32919810850697334],"average_precision_score_macro":[0.7442237019682773],"f1_score_weighted":[0.8742062417853778],"f1_score_micro":[0.8995447647951441],"average_precision_score_weighted":[0.9324602941666443],"recall_score_micro":[0.8995447647951441],"AUC_weighted":[0.9030188182948131]},"0f6f71f7-c0df-4792-89e1-8604dab13486_16":{"average_precision_score_micro":[0.8252772715869998],"matthews_correlation":[0.29867582745539095],"recall_score_weighted":[0.7065250379362671],"recall_score_micro":[0.7065250379362671],"log_loss":[0.5341635563199723],"precision_score_micro":[0.7065250379362671],"balanced_accuracy":[0.7258172222870554],"average_precision_score_weighted":[0.914149876751836],"weighted_accuracy":[0.7017353104067231],"AUC_weighted":[0.8472104133208113],"precision_score_weighted":[0.8768169965009414],"f1_score_micro":[0.7065250379362671],"f1_score_macro":[0.5867333233981185],"norm_macro_recall":[0.4516344445741107],"precision_score_macro":[0.5987604587934878],"recall_score_macro":[0.7258172222870554],"AUC_micro":[0.8173143195304422],"average_precision_score_macro":[0.6938321849583192],"AUC_macro":[0.8472104133208113],"f1_score_weighted":[0.759398156585292],"accuracy":[0.7065250379362671]},"0f6f71f7-c0df-4792-89e1-8604dab13486_13":{"recall_score_micro":[0.7708649468892261],"log_loss":[0.6144272733487015],"accuracy":[0.7708649468892261],"AUC_weighted":[0.8305209624208341],"average_precision_score_micro":[0.7868296267004975],"balanced_accuracy":[0.7502028352477647],"f1_score_macro":[0.6359243370653751],"recall_score_macro":[0.7502028352477647],"f1_score_weighted":[0.8079298900661662],"recall_score_weighted":[0.7708649468892261],"norm_macro_recall":[0.5004056704955293],"matthews_correlation":[0.3517603183907477],"average_precision_score_macro":[0.6971870701342704],"precision_score_macro":[0.6236350114416476],"AUC_macro":[0.8305209624208341],"precision_score_weighted":[0.882375179784918],"precision_score_micro":[0.7708649468892261],"average_precision_score_weighted":[0.9107692497218001],"weighted_accuracy":[0.7759947903091381],"f1_score_micro":[0.7708649468892261],"AUC_micro":[0.8256152122703964]},"0f6f71f7-c0df-4792-89e1-8604dab13486_25":{"f1_score_micro":[0.9125948406676783],"average_precision_score_micro":[0.9794040437599212],"AUC_macro":[0.9423697825495001],"recall_score_weighted":[0.9125948406676783],"log_loss":[0.19370054320418742],"precision_score_weighted":[0.9090583667022298],"precision_score_macro":[0.7834644232348487],"f1_score_weighted":[0.9106208860084958],"matthews_correlation":[0.5418671898368607],"recall_score_micro":[0.9125948406676783],"average_precision_score_macro":[0.8096965049514568],"weighted_accuracy":[0.9507390340617803],"AUC_micro":[0.9783902127884941],"accuracy":[0.9125948406676783],"balanced_accuracy":[0.75895670439958],"norm_macro_recall":[0.5179134087991599],"precision_score_micro":[0.9125948406676783],"average_precision_score_weighted":[0.9516558858697237],"f1_score_macro":[0.7704152731326646],"AUC_weighted":[0.9423697825495002],"recall_score_macro":[0.75895670439958]},"0f6f71f7-c0df-4792-89e1-8604dab13486_29":{"weighted_accuracy":[0.952584822751283],"f1_score_micro":[0.9110773899848255],"average_precision_score_micro":[0.9793451678941233],"recall_score_macro":[0.7438927140467577],"precision_score_weighted":[0.9057257611710879],"recall_score_micro":[0.9110773899848255],"average_precision_score_weighted":[0.9514074737160434],"log_loss":[0.187475349495239],"matthews_correlation":[0.5238818520157478],"recall_score_weighted":[0.9110773899848255],"AUC_micro":[0.9783121987837369],"AUC_macro":[0.9405739033466889],"f1_score_weighted":[0.9079110292671074],"average_precision_score_macro":[0.809403164149237],"balanced_accuracy":[0.7438927140467577],"accuracy":[0.9110773899848255],"precision_score_micro":[0.9110773899848255],"f1_score_macro":[0.7607040409906504],"precision_score_macro":[0.7813247168372088],"norm_macro_recall":[0.48778542809351544],"AUC_weighted":[0.9405739033466889]},"0f6f71f7-c0df-4792-89e1-8604dab13486_32":{"recall_score_macro":[0.724763683043529],"matthews_correlation":[0.49881256847663513],"f1_score_weighted":[0.9039219348737966],"average_precision_score_weighted":[0.9513421484543777],"precision_score_macro":[0.7767506466136603],"recall_score_weighted":[0.908649468892261],"balanced_accuracy":[0.724763683043529],"AUC_macro":[0.9399237191278269],"AUC_micro":[0.9783186462221465],"norm_macro_recall":[0.449527366087058],"accuracy":[0.908649468892261],"precision_score_weighted":[0.9011568762582128],"weighted_accuracy":[0.9543033354921573],"f1_score_micro":[0.908649468892261],"average_precision_score_macro":[0.809408807756427],"precision_score_micro":[0.908649468892261],"log_loss":[0.18598497314459558],"recall_score_micro":[0.908649468892261],"average_precision_score_micro":[0.9793488243667532],"f1_score_macro":[0.7469309675333606],"AUC_weighted":[0.9399237191278269]},"0f6f71f7-c0df-4792-89e1-8604dab13486_1":{"f1_score_macro":[0.7416848907681176],"log_loss":[0.1874363495858499],"precision_score_weighted":[0.8991976076061607],"AUC_micro":[0.9781770788959222],"weighted_accuracy":[0.9537972210153172],"recall_score_micro":[0.9071320182094081],"balanced_accuracy":[0.7191727470931578],"norm_macro_recall":[0.43834549418631563],"AUC_macro":[0.9392346349984347],"f1_score_weighted":[0.9021127651963996],"precision_score_macro":[0.7723958081530135],"average_precision_score_micro":[0.9791945367231853],"matthews_correlation":[0.488678780261868],"AUC_weighted":[0.9392346349984347],"f1_score_micro":[0.9071320182094081],"accuracy":[0.9071320182094081],"average_precision_score_weighted":[0.9505970434373063],"precision_score_micro":[0.9071320182094081],"average_precision_score_macro":[0.8065229883244922],"recall_score_weighted":[0.9071320182094081],"recall_score_macro":[0.7191727470931578]},"0f6f71f7-c0df-4792-89e1-8604dab13486_8":{"AUC_macro":[0.91278038036703],"balanced_accuracy":[0.5538467380572644],"matthews_correlation":[0.27511497372025834],"norm_macro_recall":[0.10769347611452873],"average_precision_score_weighted":[0.9379599175740891],"precision_score_macro":[0.8514059137835159],"precision_score_weighted":[0.8882549185070538],"log_loss":[0.24128815201365278],"precision_score_micro":[0.8974203338391502],"accuracy":[0.8974203338391502],"recall_score_macro":[0.5538467380572644],"recall_score_micro":[0.8974203338391502],"f1_score_macro":[0.5702284479431967],"average_precision_score_macro":[0.7661371123670685],"average_precision_score_micro":[0.9710946319107935],"f1_score_weighted":[0.8612300661122239],"recall_score_weighted":[0.8974203338391502],"AUC_weighted":[0.9127803803670299],"weighted_accuracy":[0.9827203641632779],"AUC_micro":[0.9703706125757285],"f1_score_micro":[0.8974203338391502]},"0f6f71f7-c0df-4792-89e1-8604dab13486_31":{"accuracy":[0.9098634294385433],"AUC_weighted":[0.9425170464965072],"log_loss":[0.1816497894889092],"matthews_correlation":[0.516257242002229],"norm_macro_recall":[0.4793135832930442],"precision_score_macro":[0.7780241883493644],"AUC_micro":[0.9791127864216947],"precision_score_weighted":[0.9042364457305064],"f1_score_micro":[0.9098634294385431],"weighted_accuracy":[0.9521211335906523],"average_precision_score_macro":[0.8168322395292584],"AUC_macro":[0.9425170464965074],"f1_score_macro":[0.7568071701272531],"average_precision_score_weighted":[0.9532509453681809],"f1_score_weighted":[0.9065259364084196],"recall_score_macro":[0.7396567916465221],"average_precision_score_micro":[0.9800831578881748],"recall_score_micro":[0.9098634294385433],"precision_score_micro":[0.9098634294385433],"balanced_accuracy":[0.7396567916465221],"recall_score_weighted":[0.9098634294385433]},"0f6f71f7-c0df-4792-89e1-8604dab13486_9":{"matthews_correlation":[0.3783826059214331],"recall_score_weighted":[0.8949924127465857],"precision_score_macro":[0.7355650770494345],"AUC_weighted":[0.9190289100430307],"AUC_macro":[0.9190289100430308],"recall_score_macro":[0.6519467552843676],"precision_score_micro":[0.8949924127465857],"precision_score_weighted":[0.8790552908395141],"norm_macro_recall":[0.30389351056873526],"recall_score_micro":[0.8949924127465857],"average_precision_score_macro":[0.7705994616102925],"log_loss":[0.2444893407125649],"f1_score_micro":[0.8949924127465857],"average_precision_score_weighted":[0.9401838380951523],"f1_score_weighted":[0.8837269532502972],"f1_score_macro":[0.6808693480952989],"AUC_micro":[0.9655472839014371],"accuracy":[0.8949924127465857],"weighted_accuracy":[0.9553340752206605],"balanced_accuracy":[0.6519467552843676],"average_precision_score_micro":[0.9607321809612321]},"0f6f71f7-c0df-4792-89e1-8604dab13486_17":{"log_loss":[0.232261508044481],"average_precision_score_macro":[0.7508963122556911],"recall_score_micro":[0.8998482549317147],"average_precision_score_weighted":[0.9348299872195364],"average_precision_score_micro":[0.9700799457901492],"precision_score_weighted":[0.88289438341389],"f1_score_weighted":[0.8856282004198504],"precision_score_micro":[0.8998482549317147],"precision_score_macro":[0.7597379928710544],"balanced_accuracy":[0.6440236770788761],"norm_macro_recall":[0.2880473541577522],"matthews_correlation":[0.3868251326394196],"weighted_accuracy":[0.9633625776748329],"accuracy":[0.8998482549317147],"recall_score_weighted":[0.8998482549317147],"AUC_weighted":[0.9109034596839475],"AUC_micro":[0.9695551958294284],"recall_score_macro":[0.6440236770788761],"f1_score_macro":[0.6790334311764553],"f1_score_micro":[0.8998482549317147],"AUC_macro":[0.9109034596839474]},"0f6f71f7-c0df-4792-89e1-8604dab13486_20":{"precision_score_micro":[0.7047040971168437],"balanced_accuracy":[0.7224236681874678],"f1_score_micro":[0.7047040971168437],"average_precision_score_macro":[0.6982968490609563],"AUC_weighted":[0.8323728760185756],"norm_macro_recall":[0.4448473363749357],"recall_score_micro":[0.7047040971168437],"accuracy":[0.7047040971168437],"weighted_accuracy":[0.7003048069262952],"f1_score_weighted":[0.7579320774824435],"average_precision_score_weighted":[0.9111841807064069],"AUC_micro":[0.8011213016457086],"matthews_correlation":[0.29406957939934797],"f1_score_macro":[0.5845512548138593],"precision_score_weighted":[0.8757110993587777],"recall_score_macro":[0.7224236681874678],"log_loss":[0.5498641273741441],"average_precision_score_micro":[0.7904113450930205],"AUC_macro":[0.8323728760185756],"precision_score_macro":[0.5971984211851311],"recall_score_weighted":[0.7047040971168437]},"0f6f71f7-c0df-4792-89e1-8604dab13486_14":{"recall_score_weighted":[0.8880121396054628],"balanced_accuracy":[0.5],"precision_score_micro":[0.8880121396054628],"average_precision_score_macro":[0.6933260002522934],"precision_score_weighted":[0.788565560086672],"recall_score_micro":[0.8880121396054628],"average_precision_score_micro":[0.9632323395955598],"recall_score_macro":[0.5],"log_loss":[0.25925738863183695],"accuracy":[0.8880121396054628],"AUC_macro":[0.88173269463385],"norm_macro_recall":[0.0],"f1_score_micro":[0.8880121396054628],"weighted_accuracy":[0.9843450583187134],"AUC_micro":[0.9639361611491178],"precision_score_macro":[0.4440060698027314],"f1_score_macro":[0.4703423886834914],"average_precision_score_weighted":[0.9175528323459033],"f1_score_weighted":[0.8353395018439429],"AUC_weighted":[0.88173269463385],"matthews_correlation":[0.0]},"0f6f71f7-c0df-4792-89e1-8604dab13486_26":{"average_precision_score_macro":[0.7621860048212048],"recall_score_weighted":[0.9025796661608497],"norm_macro_recall":[0.3408567612675444],"f1_score_macro":[0.7034797905817874],"weighted_accuracy":[0.9602165507712037],"accuracy":[0.9025796661608497],"f1_score_weighted":[0.8920347468246255],"AUC_macro":[0.9207442108597436],"precision_score_micro":[0.9025796661608497],"balanced_accuracy":[0.6704283806337722],"AUC_weighted":[0.9207442108597435],"f1_score_micro":[0.9025796661608497],"recall_score_macro":[0.6704283806337722],"precision_score_macro":[0.7653000170128346],"recall_score_micro":[0.9025796661608497],"precision_score_weighted":[0.8887696135205639],"average_precision_score_micro":[0.967458335665032],"AUC_micro":[0.969689763079665],"average_precision_score_weighted":[0.9381775670173527],"log_loss":[0.2260055895613647],"matthews_correlation":[0.42527474546043575]},"0f6f71f7-c0df-4792-89e1-8604dab13486_2":{"recall_score_micro":[0.888619119878604],"weighted_accuracy":[0.9844299089511324],"accuracy":[0.888619119878604],"balanced_accuracy":[0.502710027100271],"f1_score_macro":[0.4758844840760577],"precision_score_micro":[0.888619119878604],"average_precision_score_micro":[0.9685319363036402],"f1_score_micro":[0.888619119878604],"precision_score_weighted":[0.9010323549240192],"average_precision_score_macro":[0.7479814941481048],"recall_score_macro":[0.502710027100271],"norm_macro_recall":[0.005420054200542035],"recall_score_weighted":[0.888619119878604],"AUC_weighted":[0.9011933010649315],"precision_score_macro":[0.9442757364105678],"AUC_micro":[0.9678089531892945],"average_precision_score_weighted":[0.9325006781144876],"log_loss":[0.24117525541058762],"f1_score_weighted":[0.8368155592289684],"AUC_macro":[0.9011933010649313],"matthews_correlation":[0.06939738570480868]},"0f6f71f7-c0df-4792-89e1-8604dab13486_12":{"norm_macro_recall":[0.19400033713255782],"average_precision_score_micro":[0.9714050496548325],"f1_score_macro":[0.6314920894708129],"f1_score_weighted":[0.8758042612796753],"AUC_macro":[0.9141580855316414],"precision_score_macro":[0.796331035809679],"precision_score_micro":[0.9004552352048558],"f1_score_micro":[0.9004552352048558],"average_precision_score_weighted":[0.93827163034419],"average_precision_score_macro":[0.7677478015149035],"accuracy":[0.9004552352048558],"precision_score_weighted":[0.8829713149679826],"recall_score_macro":[0.5970001685662789],"matthews_correlation":[0.33908205747257647],"AUC_weighted":[0.9141580855316414],"AUC_micro":[0.9713197676158987],"recall_score_weighted":[0.9004552352048558],"log_loss":[0.2688810305768011],"weighted_accuracy":[0.9757949199305515],"balanced_accuracy":[0.5970001685662789],"recall_score_micro":[0.9004552352048558]},"0f6f71f7-c0df-4792-89e1-8604dab13486_11":{"precision_score_micro":[0.8594840667678301],"balanced_accuracy":[0.8486497100104289],"AUC_macro":[0.9232833562101854],"recall_score_macro":[0.8486497100104289],"AUC_micro":[0.9238332784533516],"AUC_weighted":[0.9232833562101853],"precision_score_weighted":[0.9156377635587197],"norm_macro_recall":[0.6972994200208578],"f1_score_macro":[0.7434425949684589],"average_precision_score_macro":[0.7538524365508152],"f1_score_weighted":[0.8773406289896646],"log_loss":[0.7689730397421235],"average_precision_score_weighted":[0.9370528917185053],"precision_score_macro":[0.7051025689922903],"f1_score_micro":[0.8594840667678301],"recall_score_weighted":[0.8594840667678301],"matthews_correlation":[0.5348231528329939],"accuracy":[0.8594840667678301],"weighted_accuracy":[0.8621739444863014],"recall_score_micro":[0.8594840667678301],"average_precision_score_micro":[0.9116975237335335]},"0f6f71f7-c0df-4792-89e1-8604dab13486_27":{"f1_score_weighted":[0.8920347468246255],"AUC_weighted":[0.9207266132811703],"precision_score_micro":[0.9025796661608497],"average_precision_score_micro":[0.967448365543722],"precision_score_weighted":[0.8887696135205639],"weighted_accuracy":[0.9602165507712037],"recall_score_micro":[0.9025796661608497],"precision_score_macro":[0.7653000170128346],"recall_score_macro":[0.6704283806337722],"accuracy":[0.9025796661608497],"AUC_macro":[0.9207266132811703],"recall_score_weighted":[0.9025796661608497],"balanced_accuracy":[0.6704283806337722],"f1_score_macro":[0.7034797905817874],"norm_macro_recall":[0.3408567612675444],"matthews_correlation":[0.42527474546043575],"log_loss":[0.22600528180879348],"f1_score_micro":[0.9025796661608497],"AUC_micro":[0.9696869998917751],"average_precision_score_weighted":[0.9381674567338358],"average_precision_score_macro":[0.7621811064739238]},"0f6f71f7-c0df-4792-89e1-8604dab13486_23":{"precision_score_micro":[0.8992412746585736],"AUC_micro":[0.963193416244321],"precision_score_weighted":[0.8812999108590526],"f1_score_micro":[0.8992412746585736],"recall_score_macro":[0.5868435871645115],"matthews_correlation":[0.32084635598752925],"log_loss":[0.25765894492283814],"average_precision_score_weighted":[0.9267348860372854],"precision_score_macro":[0.7963442307935424],"f1_score_weighted":[0.8723981505657483],"recall_score_weighted":[0.8992412746585736],"AUC_weighted":[0.8760824826293376],"average_precision_score_macro":[0.7348587651649301],"average_precision_score_micro":[0.9641484477792276],"weighted_accuracy":[0.9768011702488849],"norm_macro_recall":[0.17368717432902292],"balanced_accuracy":[0.5868435871645115],"accuracy":[0.8992412746585736],"AUC_macro":[0.8760824826293376],"recall_score_micro":[0.8992412746585736],"f1_score_macro":[0.6181838235088807]},"0f6f71f7-c0df-4792-89e1-8604dab13486_15":{"average_precision_score_weighted":[0.941907068025792],"AUC_weighted":[0.9229304784503758],"precision_score_macro":[0.8209803321343843],"recall_score_micro":[0.8986342943854325],"accuracy":[0.8986342943854325],"f1_score_macro":[0.5950086405614746],"precision_score_micro":[0.8986342943854325],"norm_macro_recall":[0.13984795692112773],"weighted_accuracy":[0.9802441743659802],"recall_score_weighted":[0.8986342943854325],"AUC_micro":[0.9725109779152208],"precision_score_weighted":[0.884035645400796],"f1_score_micro":[0.8986342943854325],"log_loss":[0.2155066710269115],"average_precision_score_macro":[0.7759545289847867],"recall_score_macro":[0.5699239784605639],"matthews_correlation":[0.2996279147905236],"average_precision_score_micro":[0.9737782140746726],"balanced_accuracy":[0.5699239784605639],"f1_score_weighted":[0.8671329997720811],"AUC_macro":[0.9229304784503758]},"0f6f71f7-c0df-4792-89e1-8604dab13486_18":{"AUC_macro":[0.9036634453835994],"f1_score_micro":[0.8452200303490137],"average_precision_score_micro":[0.876345809781613],"AUC_weighted":[0.9036634453835996],"f1_score_macro":[0.7221375262575862],"norm_macro_recall":[0.6528173723295674],"average_precision_score_macro":[0.7579839921162544],"precision_score_macro":[0.6876632767928365],"recall_score_micro":[0.8452200303490136],"recall_score_weighted":[0.8452200303490136],"precision_score_micro":[0.8452200303490136],"accuracy":[0.8452200303490136],"log_loss":[0.41981171462576283],"precision_score_weighted":[0.9079326145966337],"weighted_accuracy":[0.8498903782717077],"average_precision_score_weighted":[0.9351064976621543],"balanced_accuracy":[0.8264086861647837],"matthews_correlation":[0.49499464085716277],"f1_score_weighted":[0.8656495932716218],"AUC_micro":[0.8997655435075448],"recall_score_macro":[0.8264086861647837]},"0f6f71f7-c0df-4792-89e1-8604dab13486_10":{"weighted_accuracy":[0.9843450583187134],"precision_score_weighted":[0.788565560086672],"f1_score_macro":[0.4703423886834914],"average_precision_score_macro":[0.726096891674438],"average_precision_score_micro":[0.9593686512320646],"balanced_accuracy":[0.5],"f1_score_weighted":[0.8353395018439429],"f1_score_micro":[0.8880121396054628],"recall_score_macro":[0.5],"AUC_weighted":[0.8571317428827054],"matthews_correlation":[0.0],"recall_score_micro":[0.8880121396054628],"precision_score_macro":[0.4440060698027314],"log_loss":[0.27408684843995673],"average_precision_score_weighted":[0.9217075397225707],"norm_macro_recall":[0.0],"AUC_macro":[0.8571317428827057],"precision_score_micro":[0.8880121396054628],"AUC_micro":[0.9590432001400014],"accuracy":[0.8880121396054628],"recall_score_weighted":[0.8880121396054628]},"0f6f71f7-c0df-4792-89e1-8604dab13486_24":{"precision_score_micro":[0.8880121396054628],"AUC_macro":[0.8802313433250533],"norm_macro_recall":[0.0],"AUC_weighted":[0.8802313433250533],"average_precision_score_weighted":[0.9189380242550522],"recall_score_micro":[0.8880121396054628],"average_precision_score_macro":[0.7103613738321392],"recall_score_macro":[0.5],"f1_score_micro":[0.8880121396054628],"log_loss":[0.3497026042726693],"AUC_micro":[0.9636375526444859],"accuracy":[0.8880121396054628],"matthews_correlation":[0.0],"weighted_accuracy":[0.9843450583187134],"recall_score_weighted":[0.8880121396054628],"f1_score_weighted":[0.8353395018439429],"f1_score_macro":[0.4703423886834914],"balanced_accuracy":[0.5],"average_precision_score_micro":[0.9607664043621833],"precision_score_weighted":[0.788565560086672],"precision_score_macro":[0.4440060698027314]},"0f6f71f7-c0df-4792-89e1-8604dab13486_38":{"norm_macro_recall":[0.43639123677634584],"precision_score_macro":[0.7996023267762398],"AUC_micro":[0.9798506496945526],"average_precision_score_weighted":[0.9546534578490573],"weighted_accuracy":[0.9623742632625392],"accuracy":[0.9138088012139606],"balanced_accuracy":[0.7181956183881729],"recall_score_macro":[0.7181956183881729],"precision_score_micro":[0.9138088012139606],"AUC_weighted":[0.9452113283948971],"f1_score_macro":[0.7500678394160896],"f1_score_micro":[0.9138088012139606],"recall_score_weighted":[0.9138088012139606],"recall_score_micro":[0.9138088012139606],"average_precision_score_micro":[0.9807816803563876],"f1_score_weighted":[0.9070553307236097],"log_loss":[0.20252538808893247],"precision_score_weighted":[0.9047611150863775],"AUC_macro":[0.9452113283948971],"matthews_correlation":[0.511358641117864],"average_precision_score_macro":[0.8218077494192368]},"0f6f71f7-c0df-4792-89e1-8604dab13486_7":{"f1_score_weighted":[0.8738813848292685],"precision_score_weighted":[0.8737524200502865],"recall_score_micro":[0.8959028831562974],"average_precision_score_macro":[0.755719704021519],"weighted_accuracy":[0.9692787822715527],"average_precision_score_weighted":[0.9375084501055427],"AUC_macro":[0.9232588122190175],"balanced_accuracy":[0.6003576013203741],"accuracy":[0.8959028831562974],"recall_score_macro":[0.6003576013203741],"precision_score_micro":[0.8959028831562974],"AUC_micro":[0.97076482738135],"recall_score_weighted":[0.8959028831562974],"log_loss":[0.23213927964116182],"matthews_correlation":[0.3181898669730556],"AUC_weighted":[0.9232588122190176],"f1_score_macro":[0.6322119804420869],"norm_macro_recall":[0.20071520264074816],"f1_score_micro":[0.8959028831562974],"precision_score_macro":[0.7522100720630132],"average_precision_score_micro":[0.9689409485665729]},"0f6f71f7-c0df-4792-89e1-8604dab13486_22":{"average_precision_score_weighted":[0.9156000029996122],"balanced_accuracy":[0.7378030256720886],"precision_score_micro":[0.7320182094081943],"f1_score_weighted":[0.7789456041318004],"norm_macro_recall":[0.4756060513441771],"AUC_macro":[0.8321288253894159],"AUC_micro":[0.8275794704350408],"average_precision_score_macro":[0.7192818554960323],"precision_score_macro":[0.608162537113739],"f1_score_macro":[0.6062933044076838],"average_precision_score_micro":[0.8084557596832637],"matthews_correlation":[0.3207577190966211],"AUC_weighted":[0.832128825389416],"recall_score_micro":[0.7320182094081943],"log_loss":[0.5669428191995315],"f1_score_micro":[0.7320182094081943],"precision_score_weighted":[0.8795412466740833],"recall_score_weighted":[0.7320182094081943],"accuracy":[0.7320182094081943],"recall_score_macro":[0.7378030256720886],"weighted_accuracy":[0.7305819960065015]},"0f6f71f7-c0df-4792-89e1-8604dab13486_19":{"accuracy":[0.8880121396054628],"average_precision_score_macro":[0.7128627425892439],"f1_score_weighted":[0.8353395018439429],"average_precision_score_weighted":[0.9237812221571269],"average_precision_score_micro":[0.9670392365859944],"AUC_weighted":[0.8957246219762265],"precision_score_micro":[0.8880121396054628],"balanced_accuracy":[0.5],"matthews_correlation":[0.0],"precision_score_weighted":[0.788565560086672],"norm_macro_recall":[0.0],"AUC_macro":[0.8957246219762265],"f1_score_micro":[0.8880121396054628],"log_loss":[0.2650379986841843],"AUC_micro":[0.9667190597792672],"precision_score_macro":[0.4440060698027314],"recall_score_micro":[0.8880121396054628],"weighted_accuracy":[0.9843450583187134],"f1_score_macro":[0.4703423886834914],"recall_score_weighted":[0.8880121396054628],"recall_score_macro":[0.5]},"0f6f71f7-c0df-4792-89e1-8604dab13486_4":{"matthews_correlation":[0.392499279945991],"AUC_micro":[0.9697889615249111],"AUC_macro":[0.9159863813265611],"weighted_accuracy":[0.9647082305228422],"f1_score_micro":[0.9010622154779969],"precision_score_macro":[0.7661506829246687],"average_precision_score_macro":[0.7599949834402286],"f1_score_weighted":[0.8865807020316077],"balanced_accuracy":[0.6447072040781925],"recall_score_micro":[0.9010622154779969],"precision_score_weighted":[0.8844121806068286],"recall_score_macro":[0.6447072040781925],"recall_score_weighted":[0.9010622154779969],"accuracy":[0.9010622154779969],"log_loss":[0.3237422891566155],"norm_macro_recall":[0.289414408156385],"AUC_weighted":[0.9159863813265611],"precision_score_micro":[0.9010622154779969],"average_precision_score_micro":[0.968691783823596],"average_precision_score_weighted":[0.9365716431859008],"f1_score_macro":[0.6808627582404]},"0f6f71f7-c0df-4792-89e1-8604dab13486_33":{"log_loss":[0.23272289656454062],"recall_score_weighted":[0.9004552352048558],"accuracy":[0.9004552352048558],"precision_score_micro":[0.9004552352048558],"average_precision_score_weighted":[0.9412040743608816],"norm_macro_recall":[0.16084464672397925],"matthews_correlation":[0.32369063951105753],"f1_score_micro":[0.9004552352048558],"f1_score_weighted":[0.8712812338562995],"f1_score_macro":[0.610449340680571],"AUC_weighted":[0.9208173797390742],"average_precision_score_micro":[0.9736652308713766],"precision_score_macro":[0.825704436675719],"precision_score_weighted":[0.8867903401078067],"balanced_accuracy":[0.5804223233619896],"recall_score_macro":[0.5804223233619896],"AUC_micro":[0.9724187795459622],"average_precision_score_macro":[0.7738442358930686],"AUC_macro":[0.9208173797390742],"weighted_accuracy":[0.9799107504716511],"recall_score_micro":[0.9004552352048558]},"0f6f71f7-c0df-4792-89e1-8604dab13486_37":{"f1_score_weighted":[0.9081434651080684],"average_precision_score_weighted":[0.9550961558092025],"norm_macro_recall":[0.4465478181781135],"f1_score_macro":[0.753928917212026],"precision_score_macro":[0.8002272868796314],"average_precision_score_micro":[0.981157413234223],"precision_score_weighted":[0.9058258332489991],"precision_score_micro":[0.9144157814871017],"recall_score_micro":[0.9144157814871017],"recall_score_weighted":[0.9144157814871017],"weighted_accuracy":[0.9618711381033722],"AUC_weighted":[0.9466432155777471],"recall_score_macro":[0.7232739090890568],"balanced_accuracy":[0.7232739090890568],"average_precision_score_macro":[0.8230679006789022],"matthews_correlation":[0.5178143294920177],"AUC_macro":[0.9466432155777471],"AUC_micro":[0.980240996037128],"accuracy":[0.9144157814871017],"log_loss":[0.18323859937810894],"f1_score_micro":[0.9144157814871017]}}